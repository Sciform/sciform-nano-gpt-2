Implementation of the 124M GPT-2 model.

This code provides a minimal implementation of the 124M-GPT2 model as well
as the training process. The original weights as published by OpenAI are used.


Note that this code is heavily inspired by Andrej Karpathy's nanoGPT 
(https://github.com/karpathy/build-nanogpt).
However, I changed the implementation at various places, 
added a lot of explanation
as well as new features.
Enjoy !
